{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from scipy.io import arff\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_names = [\"enb\", \"edm\", \"slump\", \"scm1d\"]\n",
    "n_labels = [2, 2, 3, 16]\n",
    "\n",
    "d = dict(zip(data_names, n_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mention dataset name here\n",
    "name = \"scm1d\"\n",
    "data = arff.loadarff(\"./datasets/\" + name + \".arff\")\n",
    "data = pd.DataFrame(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting train-test in ratio  80:20\n",
    "num_targets = d[name]\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(\n",
    "    data[:, :-num_targets], \n",
    "    data[:, -num_targets:], \n",
    "    test_size = 0.2,\n",
    "    random_state = 0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to assess mse and cod\n",
    "def performance(test_labels, test_labels_pred):\n",
    "    err = []\n",
    "    cod = []\n",
    "    for i in range(test_labels.shape[1]):\n",
    "        A = test_labels.T[i]\n",
    "        B = test_labels_pred.T[i]\n",
    "\n",
    "        err.append(mean_squared_error(A, B))\n",
    "        cod.append(r2_score(A, B))\n",
    "\n",
    "    return err, cod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to build model\n",
    "def MyModel(train_data, test_data, train_label, mod):\n",
    "    if \"cat\" in mod:\n",
    "        model = CatBoostRegressor(silent = True)\n",
    "    elif \"rf\" in mod:\n",
    "        model = RandomForestRegressor()\n",
    "    elif \"gb\" in mod:\n",
    "        model = GradientBoostingRegressor()\n",
    "    \n",
    "    # Fitting model\n",
    "    model.fit(train_data, train_label)\n",
    "    \n",
    "    # Making prediction\n",
    "    pred = model.predict(test_data) \n",
    "\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function implementing proposed methodology\n",
    "def PCA_Method(train_data, test_data, train_labels, test_labels, mod):\n",
    "    # Start time\n",
    "    start = time.time()\n",
    "    \n",
    "    # Obtain variance-covariance matrix\n",
    "    cov_train_labels = np.cov(train_labels.T)\n",
    "    # Obtain eigenvalues and eigenvectors\n",
    "    eig_val_train_labels, eig_vec_train_labels = np.linalg.eig(cov_train_labels)\n",
    "    eig_val_train_labels = (eig_val_train_labels/sum(eig_val_train_labels))*100\n",
    "    \n",
    "    # Sort eigenvalues and corresponding eigenvectors\n",
    "    idx = eig_val_train_labels.argsort()[::-1]   \n",
    "    eig_val_train_labels = eig_val_train_labels[idx]\n",
    "    eig_vec_train_labels = eig_vec_train_labels[:, idx]\n",
    "    \n",
    "    # Enter the desired variance threshold\n",
    "    threshold = 95\n",
    "    # Obtain the number of eigenvalues corresponding to the threshold\n",
    "    n = eig_val_train_labels.cumsum().searchsorted(threshold) \n",
    "    \n",
    "    # Develop principal components for targets\n",
    "    PC_train_labels = np.dot(train_labels, eig_vec_train_labels)\n",
    "    PC_test_labels = np.dot(test_labels, eig_vec_train_labels)\n",
    "    \n",
    "    test_labels_pred = pd.DataFrame(columns = range(n))\n",
    "    \n",
    "    # Predict targets\n",
    "    for i in range(n + 1):\n",
    "        test_labels_pred[i] = MyModel(train_data, test_data, PC_train_labels.T[i], mod)\n",
    "\n",
    "    # Fill remaining columsn with 0\n",
    "    for i in range(n + 1, test_labels.shape[1]):\n",
    "        test_labels_pred[i] = [0]*test_labels.shape[0]\n",
    "        \n",
    "    inv_eig_vec_train_labels = np.linalg.inv(eig_vec_train_labels) \n",
    "    test_labels_pred = np.dot(test_labels_pred, inv_eig_vec_train_labels)\n",
    "    \n",
    "    # End time\n",
    "    end = time.time() - start\n",
    "\n",
    "    # Obtain performance metrics - MSE and CoD\n",
    "    err, cod = performance(test_labels, test_labels_pred) \n",
    "    \n",
    "    return err, cod, n, eig_val_train_labels.tolist(), end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict each and every target \n",
    "def Each_Method(train_data, test_data, train_labels, test_labels, mod):\n",
    "    start = time.time()\n",
    "    \n",
    "    test_labels_pred = pd.DataFrame(columns = range(train_labels.shape[1]))\n",
    "    \n",
    "    # Making predictions for each target\n",
    "    for i in range(train_labels.shape[1]):\n",
    "        test_labels_pred[i] = MyModel(train_data, test_data, train_labels.T[i], mod)\n",
    "\n",
    "    end = time.time() - start\n",
    "        \n",
    "    err, cod = performance(test_labels, test_labels_pred.T) \n",
    "    \n",
    "    return err, cod, end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to implement Multivariate Multiple Linear Regression\n",
    "def MvLR_Method(train_data, test_data, train_labels, test_labels):\n",
    "    # Start time\n",
    "    start = time.time() \n",
    "    \n",
    "    # Using simpler variables to avoid complications\n",
    "    X = train_data\n",
    "    Y = train_labels\n",
    " \n",
    "    # Function to introduce a column of 1s\n",
    "    def MakeCol(M):\n",
    "        row = np.array([1]*M.shape[0])\n",
    "        temp = np.vstack((M.T, row.T))\n",
    "        M = temp.T\n",
    "        return M\n",
    "    \n",
    "    # Introduce a column of 1s in training dataset\n",
    "    # (Additional degree of freedom accounting for intercept)\n",
    "    X = MakeCol(X)\n",
    "    \n",
    "    # Perform matrix multiplications to solve for min. B \n",
    "    # (Y = XB + E is the original equation)\n",
    "    XT_X = np.dot(X.T, X)\n",
    "    inv_XT_X = np.linalg.inv(XT_X)\n",
    "    inv_XT_X_XT = np.dot(inv_XT_X, X.T)\n",
    "    B = np.dot(inv_XT_X_XT, Y)\n",
    "    \n",
    "    # Transform test data like train data\n",
    "    D = MakeCol(test_data)\n",
    "    \n",
    "    # Make prediction on train data\n",
    "    test_labels_pred = np.dot(D, B)\n",
    "    \n",
    "    # End time\n",
    "    end = time.time() - start\n",
    "    \n",
    "    # Obtain performance metrics - MSE and CoD\n",
    "    err, cod = performance(test_labels, test_labels_pred) \n",
    "    \n",
    "    return err, cod, end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = {}\n",
    "\n",
    "models = [\"cat\", \"rf\", \"gb\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using proposed methodology\n",
    "for mod in tqdm(models):\n",
    "    err, cod, n, eig_val_train_labels, end = PCA_Method(\n",
    "        train_data, \n",
    "        test_data, \n",
    "        train_labels, \n",
    "        test_labels, \n",
    "        \"PC_\" + mod\n",
    "    )\n",
    "    temp = {}\n",
    "    temp[\"MSE\"] = err\n",
    "    temp[\"CoD\"] = cod\n",
    "    temp[\"n\"] = n\n",
    "    temp[\"eig_val\"] =  eig_val_train_labels\n",
    "    temp[\"Time\"] = end\n",
    "    summary[\"PC_\" + mod] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Multivariate Multiple Regression Technique\n",
    "err, cod, end = MvLR_Method(\n",
    "    train_data, \n",
    "    test_data, \n",
    "    train_labels, \n",
    "    test_labels\n",
    ")\n",
    "temp = {}\n",
    "temp[\"MSE\"] = err\n",
    "temp[\"CoD\"] = cod\n",
    "temp[\"Time\"] = end\n",
    "summary[\"MvLR\"] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using technique of predicting all targets\n",
    "for mod in tqdm(models):\n",
    "    err, cod, end = Each_Method(\n",
    "        train_data, \n",
    "        test_data, \n",
    "        train_labels, \n",
    "        test_labels, \n",
    "        \"Each_\" + mod\n",
    "    )\n",
    "    temp = {}\n",
    "    temp[\"MSE\"] = err\n",
    "    temp[\"CoD\"] = cod\n",
    "    temp[\"Time\"] = end\n",
    "    summary[\"Each_\" + mod] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving results\n",
    "pickle.dump(summary, open(\"summary_\" + name + \".pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
